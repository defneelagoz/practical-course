{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 32,
            "id": "f7532af0",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, argparse, joblib\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "id": "ebaa411f",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import OneHotEncoder\n",
                "from sklearn.impute import SimpleImputer\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.metrics import (\n",
                "    classification_report,\n",
                "    confusion_matrix,\n",
                "    cohen_kappa_score\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "id": "f6e3e597",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Notebook folder: C:\\Users\\beste\\OneDrive\\Masa√ºst√º\\praktikum\\practical-course\\predictive_model\\log_regression\n",
                        "Loaded 4424 rows from C:\\Users\\beste\\OneDrive\\Masa√ºst√º\\praktikum\\practical-course\\predictive_model\\student_data.csv\n"
                    ]
                }
            ],
            "source": [
                "# Current notebook folder\n",
                "base_path = Path().resolve()\n",
                "print(\"Notebook folder:\", base_path)\n",
                "\n",
                "# If notebook is already inside predictive_model\n",
                "csv_path = base_path.parent / \"student_data.csv\"\n",
                "\n",
                "# Load CSV\n",
                "df = pd.read_csv(csv_path, sep=\";\", engine=\"python\", encoding=\"utf-8-sig\")\n",
                "print(f\"Loaded {len(df)} rows from {csv_path}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "id": "b5526681",
            "metadata": {},
            "outputs": [],
            "source": [
                "def infer_columns(df: pd.DataFrame, target: str):\n",
                "    X = df.drop(columns=[target])\n",
                "    cat_cols = list(X.select_dtypes(include=[\"object\", \"category\"]).columns)\n",
                "    # d√º≈ü√ºk kart sayƒ±lƒ± tamsayƒ±larƒ± kategorik say (√∂rn. d√∂nem kodu)\n",
                "    for c in X.select_dtypes(include=[\"int64\", \"int32\", \"int16\", \"int8\"]).columns:\n",
                "        if X[c].nunique() <= 20:\n",
                "            cat_cols.append(c)\n",
                "    cat_cols = sorted(set(cat_cols))\n",
                "    num_cols = [c for c in X.columns if c not in cat_cols]\n",
                "    return num_cols, cat_cols"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "id": "8ef57a2d",
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_confusion_matrix(cm, labels, outpath=\"confusion_matrix.png\", title=\"Confusion Matrix ‚Äì Baseline\"):\n",
                "    fig, ax = plt.subplots()\n",
                "    im = ax.imshow(cm)\n",
                "    ax.set_xticks(range(len(labels))); ax.set_yticks(range(len(labels)))\n",
                "    ax.set_xticklabels(labels, rotation=45, ha=\"right\"); ax.set_yticklabels(labels)\n",
                "    for i in range(len(cm)):\n",
                "        for j in range(len(cm)):\n",
                "            ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
                "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\"); ax.set_title(title)\n",
                "    plt.tight_layout()\n",
                "    fig.savefig(outpath); plt.close(fig)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "id": "5b3fc3c3",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading CSV from: C:\\Users\\beste\\OneDrive\\Masa√ºst√º\\praktikum\\practical-course\\predictive_model\\student_data.csv\n",
                        "Loaded 4424 rows\n",
                        "\n",
                        "=== Classification Report ===\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "     Dropout      0.835     0.694     0.758       284\n",
                        "    Enrolled      0.412     0.635     0.500       159\n",
                        "    Graduate      0.866     0.792     0.827       442\n",
                        "\n",
                        "    accuracy                          0.732       885\n",
                        "   macro avg      0.704     0.707     0.695       885\n",
                        "weighted avg      0.775     0.732     0.746       885\n",
                        "\n",
                        "\n",
                        "‚≠ê Cohen Kappa Score: 0.5794\n",
                        "üñºÔ∏è Confusion matrix saved to: C:\\Users\\beste\\OneDrive\\Masa√ºst√º\\praktikum\\practical-course\\predictive_model\\log_regression\\confusion_matrix.png\n",
                        "üìÅ Predictions saved to: C:\\Users\\beste\\OneDrive\\Masa√ºst√º\\praktikum\\practical-course\\predictive_model\\log_regression\\predictions.csv\n",
                        "üíæ Model saved to: C:\\Users\\beste\\OneDrive\\Masa√ºst√º\\praktikum\\practical-course\\predictive_model\\log_regression\\baseline_model.joblib\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\beste\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
                        "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
                        "\n",
                        "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
                        "You might also want to scale the data as shown in:\n",
                        "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
                        "Please also refer to the documentation for alternative solver options:\n",
                        "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
                        "  n_iter_i = _check_optimize_result(\n"
                    ]
                }
            ],
            "source": [
                "def main():\n",
                "    parser = argparse.ArgumentParser(description=\"Baseline student outcome model (single-file).\")\n",
                "\n",
                "    parser.add_argument(\"--csv\", default=os.path.join(\"predictive_model\", \"student_data.csv\"))\n",
                "    parser.add_argument(\"--target\", default=\"Target\")\n",
                "    parser.add_argument(\"--sep\", default=\";\")\n",
                "    parser.add_argument(\"--test_size\", type=float, default=0.20)\n",
                "    parser.add_argument(\"--seed\", type=int, default=42)\n",
                "\n",
                "    parser.add_argument(\"--save_model\", default=os.path.join(\"predictive_model\", \"baseline_model.joblib\"))\n",
                "    parser.add_argument(\"--pred_out\", default=os.path.join(\"predictive_model\", \"predictions.csv\"))\n",
                "    parser.add_argument(\"--cm_out\", default=os.path.join(\"predictive_model\", \"confusion_matrix.png\"))\n",
                "\n",
                "    args = parser.parse_args(args=[])\n",
                "\n",
                "    base_path = Path().resolve()\n",
                "    args.pred_out = base_path / \"predictions.csv\"\n",
                "    args.save_model = base_path / \"baseline_model.joblib\"\n",
                "    args.cm_out = base_path / \"confusion_matrix.png\"\n",
                "\n",
                "    # ===== 1) Load CSV =====\n",
                "    csv_path = base_path.parent / \"student_data.csv\"\n",
                "    print(\"Loading CSV from:\", csv_path)\n",
                "\n",
                "    df = pd.read_csv(csv_path, sep=args.sep, engine=\"python\", encoding=\"utf-8-sig\")\n",
                "    print(f\"Loaded {len(df)} rows\")\n",
                "\n",
                "    df.columns = [str(c).replace(\"\\ufeff\", \"\").strip().replace(\" \", \"_\") for c in df.columns]\n",
                "\n",
                "    # Target detection\n",
                "    cand_target = args.target.replace(\" \", \"_\")\n",
                "    if cand_target in df.columns:\n",
                "        target_col = cand_target\n",
                "    else:\n",
                "        aliases = [\"Target\", \"target\", \"Status\", \"Outcome\", \"Result\", \"Label\"]\n",
                "        aliases = [a.replace(\" \", \"_\") for a in aliases]\n",
                "        found = [c for c in df.columns if c in aliases or c.lower() in [a.lower() for a in aliases]]\n",
                "        if found:\n",
                "            target_col = found[0]\n",
                "        else:\n",
                "            KNOWN = {\"Dropout\", \"Graduate\", \"Enrolled\"}\n",
                "            found = []\n",
                "            for c in df.columns:\n",
                "                vals = set(df[c].astype(str).str.strip().unique())\n",
                "                if len(vals - KNOWN - {\"\"}) <= 0 and len(vals & KNOWN) >= 2:\n",
                "                    found.append(c)\n",
                "            if not found:\n",
                "                raise ValueError(\"Target column not found.\")\n",
                "            target_col = found[0]\n",
                "\n",
                "    # ===== 2) Split =====\n",
                "    y = df[target_col].astype(str)\n",
                "    X = df.drop(columns=[target_col])\n",
                "\n",
                "    X_train, X_test, y_train, y_test = train_test_split(\n",
                "        X, y, test_size=args.test_size, random_state=args.seed, stratify=y\n",
                "    )\n",
                "\n",
                "    # ===== 3) Preprocess + Model =====\n",
                "    num_cols, cat_cols = infer_columns(df, target_col)\n",
                "\n",
                "    pre = ColumnTransformer(\n",
                "        [\n",
                "            (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
                "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
                "        ],\n",
                "        remainder=\"drop\"\n",
                "    )\n",
                "\n",
                "    clf = LogisticRegression(\n",
                "        max_iter=1000,\n",
                "        class_weight=\"balanced\",\n",
                "        random_state=args.seed\n",
                "    )\n",
                "\n",
                "    pipe = Pipeline([\n",
                "        (\"pre\", pre),\n",
                "        (\"clf\", clf)\n",
                "    ])\n",
                "\n",
                "    # ===== 4) Fit =====\n",
                "    pipe.fit(X_train, y_train)\n",
                "\n",
                "    # ===== 5) Evaluate =====\n",
                "    y_pred = pipe.predict(X_test)\n",
                "\n",
                "    print(\"\\n=== Classification Report ===\")\n",
                "    print(classification_report(y_test, y_pred, digits=3))\n",
                "\n",
                "    # === ‚≠ê KAPPA SCORE EKLENDƒ∞ ‚≠ê ===\n",
                "    kappa = cohen_kappa_score(y_test, y_pred)\n",
                "    print(f\"\\n‚≠ê Cohen Kappa Score: {kappa:.4f}\")\n",
                "\n",
                "    # Confusion Matrix\n",
                "    labels_sorted = sorted(y.unique())\n",
                "    cm = confusion_matrix(y_test, y_pred, labels=labels_sorted)\n",
                "    plot_confusion_matrix(cm, labels_sorted, outpath=args.cm_out)\n",
                "    print(f\"üñºÔ∏è Confusion matrix saved to: {args.cm_out}\")\n",
                "\n",
                "    # ===== 6) Predict on full CSV =====\n",
                "    proba = pipe.predict_proba(X)\n",
                "    out = df.copy()\n",
                "    out[\"prediction\"] = pipe.predict(X)\n",
                "    classes = pipe.named_steps[\"clf\"].classes_\n",
                "\n",
                "    for i, c in enumerate(classes):\n",
                "        out[f\"p_{c}\"] = proba[:, i]\n",
                "\n",
                "    out.to_csv(args.pred_out, index=False)\n",
                "    print(f\"üìÅ Predictions saved to: {args.pred_out}\")\n",
                "\n",
                "    # ===== 7) Save Model =====\n",
                "    joblib.dump(pipe, args.save_model)\n",
                "    print(f\"üíæ Model saved to: {args.save_model}\")\n",
                "\n",
                "\n",
                "main()\n",
                "\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
