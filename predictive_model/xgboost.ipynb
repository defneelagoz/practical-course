{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "f7532af0",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, argparse, joblib\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "ebaa411f",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
                "from sklearn.impute import SimpleImputer\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.pipeline import Pipeline\n",
                "from xgboost import XGBClassifier\n",
                "from sklearn.metrics import classification_report, confusion_matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "f6e3e597",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Notebook folder: C:\\Users\\wwwut\\practical-course\\predictive_model\n",
                        "Loaded 4424 rows from C:\\Users\\wwwut\\practical-course\\predictive_model\\student_data.csv\n"
                    ]
                }
            ],
            "source": [
                "# Current notebook folder\n",
                "base_path = Path().resolve()\n",
                "print(\"Notebook folder:\", base_path)\n",
                "\n",
                "# If notebook is already inside predictive_model\n",
                "csv_path = base_path / \"student_data.csv\"\n",
                "\n",
                "# Load CSV\n",
                "df = pd.read_csv(csv_path, sep=\";\", engine=\"python\", encoding=\"utf-8-sig\")\n",
                "print(f\"Loaded {len(df)} rows from {csv_path}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "b5526681",
            "metadata": {},
            "outputs": [],
            "source": [
                "def infer_columns(df: pd.DataFrame, target: str):\n",
                "    X = df.drop(columns=[target])\n",
                "    cat_cols = list(X.select_dtypes(include=[\"object\", \"category\"]).columns)\n",
                "    # d√º≈ü√ºk kart sayƒ±lƒ± tamsayƒ±larƒ± kategorik say (√∂rn. d√∂nem kodu)\n",
                "    for c in X.select_dtypes(include=[\"int64\", \"int32\", \"int16\", \"int8\"]).columns:\n",
                "        if X[c].nunique() <= 20:\n",
                "            cat_cols.append(c)\n",
                "    cat_cols = sorted(set(cat_cols))\n",
                "    num_cols = [c for c in X.columns if c not in cat_cols]\n",
                "    return num_cols, cat_cols"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "8ef57a2d",
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_confusion_matrix(cm, labels, outpath=\"confusion_matrix.png\", title=\"Confusion Matrix ‚Äì XGBoost\"):\n",
                "    fig, ax = plt.subplots()\n",
                "    im = ax.imshow(cm)\n",
                "    ax.set_xticks(range(len(labels))); ax.set_yticks(range(len(labels)))\n",
                "    ax.set_xticklabels(labels, rotation=45, ha=\"right\"); ax.set_yticklabels(labels)\n",
                "    for i in range(len(cm)):\n",
                "        for j in range(len(cm)):\n",
                "            ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
                "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\"); ax.set_title(title)\n",
                "    plt.tight_layout()\n",
                "    fig.savefig(outpath); plt.close(fig)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "5b3fc3c3",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading CSV from: C:\\Users\\wwwut\\practical-course\\predictive_model\\student_data.csv\n",
                        "Loaded 4424 rows from C:\\Users\\wwwut\\practical-course\\predictive_model\\student_data.csv\n",
                        "=== Classification Report (test set) ===\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "     Dropout      0.788     0.746     0.767       284\n",
                        "    Enrolled      0.512     0.403     0.451       159\n",
                        "    Graduate      0.813     0.903     0.855       442\n",
                        "\n",
                        "    accuracy                          0.763       885\n",
                        "   macro avg      0.704     0.684     0.691       885\n",
                        "weighted avg      0.751     0.763     0.754       885\n",
                        "\n",
                        "üñºÔ∏è Saved confusion matrix to C:\\Users\\wwwut\\practical-course\\predictive_model\\xgboost_confusion_matrix.png\n",
                        "‚úÖ Wrote predictions to C:\\Users\\wwwut\\practical-course\\predictive_model\\xgboost_predictions.csv\n",
                        "üíæ Saved model to C:\\Users\\wwwut\\practical-course\\predictive_model\\xgboost_model.joblib\n"
                    ]
                }
            ],
            "source": [
                "def main():\n",
                "    parser = argparse.ArgumentParser(description=\"XGBoost student outcome model (single-file).\")\n",
                "    # >>> ekrandaki isimlere ve yerlere g√∂re varsayƒ±lanlarƒ± koydum\n",
                "    parser.add_argument(\"--csv\", default=os.path.join(\"predictive_model\", \"student_data.csv\"),\n",
                "                        help=\"CSV yolu (default: predictive_model/student_data.csv)\")\n",
                "    parser.add_argument(\"--target\", default=\"Target\", help=\"Hedef s√ºtun adƒ± (default: Target)\")\n",
                "    parser.add_argument(\"--sep\", default=\";\", help=\"CSV ayra√ß (default: ;)\")  # noktalƒ± virg√ºl\n",
                "    parser.add_argument(\"--test_size\", type=float, default=0.20, help=\"Test oranƒ± (default: 0.20)\")\n",
                "    parser.add_argument(\"--seed\", type=int, default=42, help=\"Rastgele tohum (default: 42)\")\n",
                "    # √ßƒ±ktƒ± dosyalarƒ±nƒ± aynƒ± klas√∂re alalƒ±m ki kolay bul\n",
                "    parser.add_argument(\"--save_model\", default=os.path.join(\"predictive_model\", \"xgboost_model.joblib\"),\n",
                "                        help=\"Model kaydetme yolu\")\n",
                "    parser.add_argument(\"--pred_out\", default=os.path.join(\"predictive_model\", \"xgboost_predictions.csv\"),\n",
                "                        help=\"Tahmin √ßƒ±ktƒ±sƒ± CSV yolu\")\n",
                "    parser.add_argument(\"--cm_out\", default=os.path.join(\"predictive_model\", \"xgboost_confusion_matrix.png\"),\n",
                "                        help=\"Karƒ±≈üƒ±klƒ±k matrisi g√∂rsel yolu\")\n",
                "    args = parser.parse_args(args=[])\n",
                "\n",
                "    base_path = Path().resolve()\n",
                "    args.pred_out = base_path / \"xgboost_predictions.csv\"\n",
                "    args.save_model = base_path / \"xgboost_model.joblib\"\n",
                "    args.cm_out = base_path / \"xgboost_confusion_matrix.png\"\n",
                "\n",
                "\n",
                "    # 1) Veri\n",
                "    # 1) Load data (handle BOM + weird spaces) and detect target column\n",
                "    base_path = Path().resolve()\n",
                "    \n",
                "    # CSV relative to notebook\n",
                "    csv_path = base_path / \"student_data.csv\"  # <- no extra \"predictive_model\"\n",
                "    print(\"Loading CSV from:\", csv_path)\n",
                "\n",
                "    # Load CSV\n",
                "    df = pd.read_csv(csv_path, sep=\";\", engine=\"python\", encoding=\"utf-8-sig\")\n",
                "    print(f\"Loaded {len(df)} rows from {csv_path}\")\n",
                "\n",
                "    # normalize headers\n",
                "    clean_cols = []\n",
                "    for c in df.columns:\n",
                "        c2 = str(c).replace(\"\\ufeff\", \"\").strip().replace(\" \", \"_\")\n",
                "        clean_cols.append(c2)\n",
                "    df.columns = clean_cols\n",
                "\n",
                "    # try the provided target, then common aliases, then infer by values\n",
                "    cand_target = args.target.replace(\" \", \"_\")\n",
                "    if cand_target in df.columns:\n",
                "        target_col = cand_target\n",
                "    else:\n",
                "        # common alternatives people use\n",
                "        aliases = [\"Target\", \"target\", \"Status\", \"Outcome\", \"Result\", \"Label\"]\n",
                "        aliases = [a.replace(\" \", \"_\") for a in aliases]\n",
                "        found = [c for c in df.columns if c in aliases or c.lower() in [a.lower() for a in aliases]]\n",
                "        if found:\n",
                "            target_col = found[0]\n",
                "        else:\n",
                "            # infer: column whose unique values are subset of the known classes\n",
                "            KNOWN = {\"Dropout\", \"Graduate\", \"Enrolled\"}\n",
                "            found = []\n",
                "            for c in df.columns:\n",
                "                vals = set(df[c].astype(str).str.strip().unique())\n",
                "                # accept if mostly within known set (allow a few NaN/empty)\n",
                "                if len(vals - KNOWN - {\"\"}) <= 0 and len(vals & KNOWN) >= 2:\n",
                "                    found.append(c)\n",
                "            if not found:\n",
                "                raise ValueError(\n",
                "                    f\"Couldn't find the target column. Columns: {list(df.columns)[:15]} ... \"\n",
                "                    \"Pass --target CorrectName or open the CSV to check the exact header.\"\n",
                "                )\n",
                "            target_col = found[0]\n",
                "\n",
                "    # 2) Split\n",
                "    # XGBoost requires integer-encoded labels\n",
                "    le = LabelEncoder()\n",
                "    y = le.fit_transform(df[target_col].astype(str))\n",
                "    X = df.drop(columns=[target_col])\n",
                "    X_train, X_test, y_train, y_test = train_test_split(\n",
                "        X, y, test_size=args.test_size, random_state=args.seed, stratify=y\n",
                "    )\n",
                "\n",
                "    # 3) Preprocess & Model\n",
                "    num_cols, cat_cols = infer_columns(df, target_col)\n",
                "    pre = ColumnTransformer(\n",
                "        transformers=[\n",
                "            (\"num\", SimpleImputer(strategy=\"median\"), num_cols),\n",
                "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
                "        ],\n",
                "        remainder=\"drop\"\n",
                "    )\n",
                "    # XGBoost\n",
                "    clf = XGBClassifier(random_state=args.seed)\n",
                "    pipe = Pipeline([(\"pre\", pre), (\"clf\", clf)])\n",
                "\n",
                "    # 4) Fit\n",
                "    pipe.fit(X_train, y_train)\n",
                "\n",
                "    # 5) Evaluate\n",
                "    y_pred = pipe.predict(X_test)\n",
                "    print(\"=== Classification Report (test set) ===\")\n",
                "    # Convert back to original labels for report\n",
                "    print(classification_report(le.inverse_transform(y_test), le.inverse_transform(y_pred), digits=3))\n",
                "\n",
                "    labels_sorted = sorted(le.classes_)\n",
                "\n",
                "    # Update the confusion matrix path to notebook folder\n",
                "    args.cm_out = Path().resolve() / \"xgboost_confusion_matrix.png\"\n",
                "\n",
                "    # Plot and save confusion matrix\n",
                "    # Use original labels for confusion matrix\n",
                "    cm = confusion_matrix(le.inverse_transform(y_test), le.inverse_transform(y_pred), labels=labels_sorted)\n",
                "    plot_confusion_matrix(cm, labels_sorted, outpath=args.cm_out)\n",
                "    print(f\"üñºÔ∏è Saved confusion matrix to {args.cm_out}\")\n",
                "\n",
                "    # 6) Full CSV √ºzerinde tahmin\n",
                "    proba = pipe.predict_proba(X)\n",
                "    out = df.copy()\n",
                "    out[\"prediction\"] = le.inverse_transform(pipe.predict(X))\n",
                "    # classes_ in XGBClassifier are integers 0..N-1, so we map them back\n",
                "    classes_indices = pipe.named_steps[\"clf\"].classes_\n",
                "    for i, c_idx in enumerate(classes_indices):\n",
                "        c_label = le.inverse_transform([c_idx])[0]\n",
                "        out[f\"p_{c_label}\"] = proba[:, i]\n",
                "    out.to_csv(args.pred_out, index=False)\n",
                "    print(f\"‚úÖ Wrote predictions to {args.pred_out}\")\n",
                "\n",
                "    # 7) Modeli kaydet\n",
                "    if args.save_model:\n",
                "        joblib.dump(pipe, args.save_model)\n",
                "        print(f\"üíæ Saved model to {args.save_model}\")\n",
                "\n",
                "main()\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
